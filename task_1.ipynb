{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72291a4e",
   "metadata": {},
   "source": [
    "# Data Visualiztion Course Final Projet\n",
    "> by Kfir Goldfarb\n",
    "\n",
    "<a href=\"https://github.com/kggold4\"><img src=\"images/github.png\" width=\"25px\" height=\"25px\" align=\"left\"></a>\n",
    "<a href=\"https://www.linkedin.com/in/kfir-goldfarb/\"><img src=\"images/in.png\"  width=\"25px\" height=\"25px\" align=\"left\"></a>\n",
    "<a href=\"mailto:kfir.goldfarb@msmail.ariel.ac.il\"><img src=\"images/email.png\" width=\"25px\" height=\"25px\" align=\"left\"></a>\n",
    "<a href=\"https://www.youtube.com/channel/UCypEWlruyG_I5A48GqB5c6g\"><img src=\"images/youtube.png\" width=\"25px\" height=\"25px\" align=\"left\"></a>\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "# Jupyter Notebook Number 1\n",
    "<i>Improving My <a href=\"https://github.com/kggold4/final-project-intro-data-science/blob/main/notebook3.ipynb\">Introduction to Data Science Course Final Project Classification Problem</a></i>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d05c3a",
   "metadata": {},
   "source": [
    "# First let's start this task like the original task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97b3b6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274618bf",
   "metadata": {},
   "source": [
    "the dataset I'm using for the classification problem is from:\n",
    "https://www.kaggle.com/spscientist/students-performance-in-exams\n",
    "\n",
    "### this dataset deals with different grades of students according to 3 topics:\n",
    "\n",
    "1. math score\n",
    "2. reading score\n",
    "3. writing score\n",
    "\n",
    "### this information we have about a student is:\n",
    "\n",
    "1. gender\n",
    "2. race/ethnicity\n",
    "3. parental level of education\n",
    "4. lunch\n",
    "5. test preparation course\n",
    "\n",
    "# The goal of my machine learning model:\n",
    "\n",
    "After the data preparation, I want to take for each student the three scores: math score, reading score and writing score and merge them to one feature by the mean of the three, this feature will called average.\n",
    "After that process we have one feature called average and have a number value between 0 and 100, i want to classified the scores to two main classes:\n",
    "\n",
    "1. 1, if x >= 60 ('pass')\n",
    "2. 0, else ('fail')\n",
    "\n",
    "Now, the goal of the model by a given a data of a student is to predict what is the status of the student, if the studet is fail ('0') or pass ('1') in the tests score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95c01b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data:\n",
    "students = pd.read_csv('data/task_1/students.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d24af74c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>race/ethnicity</th>\n",
       "      <th>parental level of education</th>\n",
       "      <th>lunch</th>\n",
       "      <th>test preparation course</th>\n",
       "      <th>math score</th>\n",
       "      <th>reading score</th>\n",
       "      <th>writing score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female</td>\n",
       "      <td>group B</td>\n",
       "      <td>bachelor's degree</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>group C</td>\n",
       "      <td>some college</td>\n",
       "      <td>standard</td>\n",
       "      <td>completed</td>\n",
       "      <td>69</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>group B</td>\n",
       "      <td>master's degree</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>90</td>\n",
       "      <td>95</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>group A</td>\n",
       "      <td>associate's degree</td>\n",
       "      <td>free/reduced</td>\n",
       "      <td>none</td>\n",
       "      <td>47</td>\n",
       "      <td>57</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>group C</td>\n",
       "      <td>some college</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>76</td>\n",
       "      <td>78</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender race/ethnicity parental level of education         lunch  \\\n",
       "0  female        group B           bachelor's degree      standard   \n",
       "1  female        group C                some college      standard   \n",
       "2  female        group B             master's degree      standard   \n",
       "3    male        group A          associate's degree  free/reduced   \n",
       "4    male        group C                some college      standard   \n",
       "\n",
       "  test preparation course  math score  reading score  writing score  \n",
       "0                    none          72             72             74  \n",
       "1               completed          69             90             88  \n",
       "2                    none          90             95             93  \n",
       "3                    none          47             57             44  \n",
       "4                    none          76             78             75  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first five students:\n",
    "students.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634421d3",
   "metadata": {},
   "source": [
    "## <i>Dataset Features:</i>\n",
    "1. gender - the sex of the student (male or female)\n",
    "2. race/ethnicity - the race/ethnicity of the student (groups) - (details on the groups below)\n",
    "3. parental level of education - the parental level of education of the student (the parents of his) - (details on the groups below)\n",
    "4. lunch - if the student ate a lunch before the exams\n",
    "5. test preparation course - if the student take a test preparation course\n",
    "6. math score\n",
    "7. reading score\n",
    "8. writing score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0770fba",
   "metadata": {},
   "source": [
    "## <i>Preparing the data:</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64f2ee97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>race/ethnicity</th>\n",
       "      <th>parental level of education</th>\n",
       "      <th>lunch</th>\n",
       "      <th>test preparation course</th>\n",
       "      <th>math score</th>\n",
       "      <th>reading score</th>\n",
       "      <th>writing score</th>\n",
       "      <th>average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female</td>\n",
       "      <td>group B</td>\n",
       "      <td>bachelor's degree</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>74</td>\n",
       "      <td>72.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>group C</td>\n",
       "      <td>some college</td>\n",
       "      <td>standard</td>\n",
       "      <td>completed</td>\n",
       "      <td>69</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "      <td>82.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>group B</td>\n",
       "      <td>master's degree</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>90</td>\n",
       "      <td>95</td>\n",
       "      <td>93</td>\n",
       "      <td>92.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>group A</td>\n",
       "      <td>associate's degree</td>\n",
       "      <td>free/reduced</td>\n",
       "      <td>none</td>\n",
       "      <td>47</td>\n",
       "      <td>57</td>\n",
       "      <td>44</td>\n",
       "      <td>49.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>group C</td>\n",
       "      <td>some college</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>76</td>\n",
       "      <td>78</td>\n",
       "      <td>75</td>\n",
       "      <td>76.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender race/ethnicity parental level of education         lunch  \\\n",
       "0  female        group B           bachelor's degree      standard   \n",
       "1  female        group C                some college      standard   \n",
       "2  female        group B             master's degree      standard   \n",
       "3    male        group A          associate's degree  free/reduced   \n",
       "4    male        group C                some college      standard   \n",
       "\n",
       "  test preparation course  math score  reading score  writing score    average  \n",
       "0                    none          72             72             74  72.666667  \n",
       "1               completed          69             90             88  82.333333  \n",
       "2                    none          90             95             93  92.666667  \n",
       "3                    none          47             57             44  49.333333  \n",
       "4                    none          76             78             75  76.333333  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding the average score feature for each student with the average of math, reading and writing score\n",
    "# the assign ,method is to change every average value in average target for each row\n",
    "students = students.assign(average= lambda x: ((x['math score'] + x['reading score'] + x['writing score']) / 3.0))\n",
    "students.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c9ddffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>race/ethnicity</th>\n",
       "      <th>parental level of education</th>\n",
       "      <th>lunch</th>\n",
       "      <th>test preparation course</th>\n",
       "      <th>math score</th>\n",
       "      <th>reading score</th>\n",
       "      <th>writing score</th>\n",
       "      <th>average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>group B</td>\n",
       "      <td>bachelor's degree</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>74</td>\n",
       "      <td>72.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>group C</td>\n",
       "      <td>some college</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "      <td>82.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>group B</td>\n",
       "      <td>master's degree</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>95</td>\n",
       "      <td>93</td>\n",
       "      <td>92.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>group A</td>\n",
       "      <td>associate's degree</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>57</td>\n",
       "      <td>44</td>\n",
       "      <td>49.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>group C</td>\n",
       "      <td>some college</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>78</td>\n",
       "      <td>75</td>\n",
       "      <td>76.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender race/ethnicity parental level of education  lunch  \\\n",
       "0       0        group B           bachelor's degree      1   \n",
       "1       0        group C                some college      1   \n",
       "2       0        group B             master's degree      1   \n",
       "3       1        group A          associate's degree      0   \n",
       "4       1        group C                some college      1   \n",
       "\n",
       "   test preparation course  math score  reading score  writing score  \\\n",
       "0                        1          72             72             74   \n",
       "1                        0          69             90             88   \n",
       "2                        1          90             95             93   \n",
       "3                        1          47             57             44   \n",
       "4                        1          76             78             75   \n",
       "\n",
       "     average  \n",
       "0  72.666667  \n",
       "1  82.333333  \n",
       "2  92.666667  \n",
       "3  49.333333  \n",
       "4  76.333333  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for preparing all the binary values of text (string objects) in the data set:\n",
    "# I used the LabelEncoder from sklearn.preprocessing library,\n",
    "# that helping me to convert all the binary values of texetual data to a numbers\n",
    "\n",
    "lc = LabelEncoder()\n",
    "\n",
    "# preparing the 'gender' feature to binary numbers (0 = female, 1 = male)\n",
    "students['gender'] = lc.fit_transform(students['gender'])\n",
    "\n",
    "# preparing the 'lunch' feature to binary numbers (0 = free/reduced\t, 1 = standard)\n",
    "students['lunch'] = lc.fit_transform(students['lunch'])\n",
    "\n",
    "# preparing the 'lunch' feature to binary numbers (0 = completed, 1 = none)\n",
    "students['test preparation course'] = lc.fit_transform(students['test preparation course'])\n",
    "\n",
    "# showing results\n",
    "students.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78482a51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>lunch</th>\n",
       "      <th>test preparation course</th>\n",
       "      <th>average</th>\n",
       "      <th>race/ethnicity_group A</th>\n",
       "      <th>race/ethnicity_group B</th>\n",
       "      <th>race/ethnicity_group C</th>\n",
       "      <th>race/ethnicity_group D</th>\n",
       "      <th>race/ethnicity_group E</th>\n",
       "      <th>parental level of education_associate's degree</th>\n",
       "      <th>parental level of education_bachelor's degree</th>\n",
       "      <th>parental level of education_high school</th>\n",
       "      <th>parental level of education_master's degree</th>\n",
       "      <th>parental level of education_some college</th>\n",
       "      <th>parental level of education_some high school</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  lunch  test preparation course  average  race/ethnicity_group A  \\\n",
       "0       0      1                        1        1                       0   \n",
       "1       0      1                        0        1                       0   \n",
       "2       0      1                        1        1                       0   \n",
       "3       1      0                        1        0                       1   \n",
       "4       1      1                        1        1                       0   \n",
       "5       0      1                        1        1                       0   \n",
       "6       0      1                        0        1                       0   \n",
       "7       1      0                        1        0                       0   \n",
       "8       1      0                        0        1                       0   \n",
       "9       0      0                        1        0                       0   \n",
       "\n",
       "   race/ethnicity_group B  race/ethnicity_group C  race/ethnicity_group D  \\\n",
       "0                       1                       0                       0   \n",
       "1                       0                       1                       0   \n",
       "2                       1                       0                       0   \n",
       "3                       0                       0                       0   \n",
       "4                       0                       1                       0   \n",
       "5                       1                       0                       0   \n",
       "6                       1                       0                       0   \n",
       "7                       1                       0                       0   \n",
       "8                       0                       0                       1   \n",
       "9                       1                       0                       0   \n",
       "\n",
       "   race/ethnicity_group E  parental level of education_associate's degree  \\\n",
       "0                       0                                               0   \n",
       "1                       0                                               0   \n",
       "2                       0                                               0   \n",
       "3                       0                                               1   \n",
       "4                       0                                               0   \n",
       "5                       0                                               1   \n",
       "6                       0                                               0   \n",
       "7                       0                                               0   \n",
       "8                       0                                               0   \n",
       "9                       0                                               0   \n",
       "\n",
       "   parental level of education_bachelor's degree  \\\n",
       "0                                              1   \n",
       "1                                              0   \n",
       "2                                              0   \n",
       "3                                              0   \n",
       "4                                              0   \n",
       "5                                              0   \n",
       "6                                              0   \n",
       "7                                              0   \n",
       "8                                              0   \n",
       "9                                              0   \n",
       "\n",
       "   parental level of education_high school  \\\n",
       "0                                        0   \n",
       "1                                        0   \n",
       "2                                        0   \n",
       "3                                        0   \n",
       "4                                        0   \n",
       "5                                        0   \n",
       "6                                        0   \n",
       "7                                        0   \n",
       "8                                        1   \n",
       "9                                        1   \n",
       "\n",
       "   parental level of education_master's degree  \\\n",
       "0                                            0   \n",
       "1                                            0   \n",
       "2                                            1   \n",
       "3                                            0   \n",
       "4                                            0   \n",
       "5                                            0   \n",
       "6                                            0   \n",
       "7                                            0   \n",
       "8                                            0   \n",
       "9                                            0   \n",
       "\n",
       "   parental level of education_some college  \\\n",
       "0                                         0   \n",
       "1                                         1   \n",
       "2                                         0   \n",
       "3                                         0   \n",
       "4                                         1   \n",
       "5                                         0   \n",
       "6                                         1   \n",
       "7                                         1   \n",
       "8                                         0   \n",
       "9                                         0   \n",
       "\n",
       "   parental level of education_some high school  \n",
       "0                                             0  \n",
       "1                                             0  \n",
       "2                                             0  \n",
       "3                                             0  \n",
       "4                                             0  \n",
       "5                                             0  \n",
       "6                                             0  \n",
       "7                                             0  \n",
       "8                                             0  \n",
       "9                                             0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dummies varables for 'race/ethnicity' feature:\n",
    "students = pd.get_dummies(students, columns=['race/ethnicity'])\n",
    "\n",
    "# create dummies varables for 'parental level of education' feature:\n",
    "students = pd.get_dummies(students, columns=['parental level of education'])\n",
    "\n",
    "# droping the math score, reading score and writing score features\n",
    "students.drop('math score', inplace=True, axis = 1)\n",
    "students.drop('reading score', inplace=True, axis = 1)\n",
    "students.drop('writing score', inplace=True, axis = 1)\n",
    "\n",
    "# classified the average score feature as: if x >= 60 - 1 ('pass'), else - 0 ('fail')\n",
    "students['average'] = students['average'].apply(lambda x: 1 if x >= 60 else 0)\n",
    "students.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bea8bd",
   "metadata": {},
   "source": [
    "### Separate data to training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "798dabb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['gender','lunch','test preparation course','race/ethnicity_group A','race/ethnicity_group B',\n",
    "                'race/ethnicity_group C', 'race/ethnicity_group D', 'race/ethnicity_group E',\n",
    "                'parental level of education_associate\\'s degree', 'parental level of education_bachelor\\'s degree',\n",
    "                'parental level of education_high school', 'parental level of education_master\\'s degree',\n",
    "                'parental level of education_some college', 'parental level of education_some high school']\n",
    "X = students[feature_cols]\n",
    "y = students['average']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2cf8df",
   "metadata": {},
   "source": [
    "#### Print Accuracy function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd517890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that print the accuracy\n",
    "def print_accuracy(clf, X_train, X_test, y_train, y_test):\n",
    "    # fit the train data to the model\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # get the pridictions of X_test\n",
    "    pridictions = clf.predict(X_test)\n",
    "\n",
    "    # get the accuracy of the model\n",
    "    accuracy = clf.score(X_test, y_test)\n",
    "\n",
    "    # print the accuracy\n",
    "    print('accuracy of the model is: {} %'.format(\"%.2f\" % (accuracy * 100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcc31ec",
   "metadata": {},
   "source": [
    "### Using KNeighborsClassifier model\n",
    "#### Accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b25a6b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of the model is: 70.40 %\n"
     ]
    }
   ],
   "source": [
    "# get the classifier (found that 5 neighbors is the best predicter)\n",
    "nclf = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# print accuracy\n",
    "print_accuracy(nclf, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e6c107",
   "metadata": {},
   "source": [
    "### Using DecisionTreeClassifier model\n",
    "#### Accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5317e5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of the model is: 72.40 %\n"
     ]
    }
   ],
   "source": [
    "# get the classifier \n",
    "dclf = DecisionTreeClassifier()\n",
    "\n",
    "# print accuracy\n",
    "print_accuracy(dclf, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4374f9",
   "metadata": {},
   "source": [
    "### Using LogisticRegression classifier model\n",
    "#### Accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d5f53ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of the model is: 77.60 %\n"
     ]
    }
   ],
   "source": [
    "# get the classifier \n",
    "lclf = LogisticRegression()\n",
    "\n",
    "# print accuracy\n",
    "print_accuracy(lclf, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c607c899",
   "metadata": {},
   "source": [
    "### Up to this point, I have briefly shown what I did in the final project of  introduction to data science course in the classification problem in the third notebook using three models:\n",
    "\n",
    "1. KNeighborsClassifier   ~ 70.40 % accuracy\n",
    "2. DecisionTreeClassifier ~ 71.60 % accuracy\n",
    "3. LogisticRegression     ~ 77.60 % accuracy\n",
    "\n",
    "## We will now use ensemble and unsupervised learning to see if we can get a machine learning model with better accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b02d898",
   "metadata": {},
   "source": [
    "# <i>Ensemble learning</i>\n",
    "### Using Hard VotingClassifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "432c774d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('nlf', KNeighborsClassifier()),\n",
       "                             ('dlf', DecisionTreeClassifier()),\n",
       "                             ('llf', LogisticRegression())])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('nlf', nclf), ('dlf', dclf), ('llf', lclf)],\n",
    "    voting='hard')\n",
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf72f68a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier 70.40 %\n",
      "DecisionTreeClassifier 71.60 %\n",
      "LogisticRegression 77.60 %\n",
      "VotingClassifier 74.80 %\n"
     ]
    }
   ],
   "source": [
    "for clf in (nclf, dclf, lclf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, \"{:.2f}\".format(accuracy_score(y_test, y_pred) * 100), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e07a763",
   "metadata": {},
   "source": [
    "### Using Soft VotingClassifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f16de050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('nlf', KNeighborsClassifier()),\n",
       "                             ('dlf', DecisionTreeClassifier()),\n",
       "                             ('llf', LogisticRegression())],\n",
       "                 voting='soft')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('nlf', nclf), ('dlf', dclf), ('llf', lclf)],\n",
    "    voting='soft')\n",
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e20050e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier 70.40 %\n",
      "DecisionTreeClassifier 72.00 %\n",
      "LogisticRegression 77.60 %\n",
      "VotingClassifier 76.80 %\n"
     ]
    }
   ],
   "source": [
    "for clf in (nclf, dclf, lclf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, \"{:.2f}\".format(accuracy_score(y_test, y_pred) * 100), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d157a7",
   "metadata": {},
   "source": [
    "### As we can see the hard and soft voting classifiers didn't give us better accuracy than logistic regression, but the soft voting classifier gives better accuracy (76.80%) then the hard voring classifier accuracy (74.80 %)\n",
    "<br>\n",
    "\n",
    "# <i>Bagging and Pasting</i>\n",
    "\n",
    "* Use the same training algorithm for every preditor and train them on different random subsets of training set.\n",
    "    * ```Bagging``` is when sampling is perfomed with replacement.\n",
    "    * ```Pasting``` is when sampling is prefomed without repalcement.\n",
    "    \n",
    "* Parameters:\n",
    "    * Classifier to use\n",
    "    * ```n_estimators``` number of ensembles\n",
    "    * ```max_samples``` number of samples\n",
    "    * ```bootstrap``` True for bagging and False for pasting\n",
    "    * ```n_jobs``` the number of cpu's to use in the computer (when the parameter is equal to -1 the model will use all the available cpu's)\n",
    "\n",
    "###  Bagging (enstimators=500 and max_samples=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15b4f46e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of the model is: 76.80 %\n"
     ]
    }
   ],
   "source": [
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(), n_estimators=500,\n",
    "    max_samples=100, bootstrap=True, n_jobs=-1)\n",
    "\n",
    "# print accuracy\n",
    "print_accuracy(bag_clf, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8083596d",
   "metadata": {},
   "source": [
    "###  Bagging (enstimators=100 and max_samples=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bcfc7d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of the model is: 75.20 %\n"
     ]
    }
   ],
   "source": [
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(), n_estimators=100,\n",
    "    max_samples=50, bootstrap=True, n_jobs=-1)\n",
    "\n",
    "# print accuracy\n",
    "print_accuracy(bag_clf, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba15682",
   "metadata": {},
   "source": [
    "###  Pasting (enstimators=500 and max_samples=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ab7d664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of the model is: 77.60 %\n"
     ]
    }
   ],
   "source": [
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(), n_estimators=500,\n",
    "    max_samples=100, bootstrap=False, n_jobs=-1)\n",
    "\n",
    "# print accuracy\n",
    "print_accuracy(bag_clf, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e546b690",
   "metadata": {},
   "source": [
    "###  Pasting (enstimators=100 and max_samples=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f1fbc98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of the model is: 76.00 %\n"
     ]
    }
   ],
   "source": [
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(), n_estimators=100,\n",
    "    max_samples=50, bootstrap=False, n_jobs=-1)\n",
    "\n",
    "# print accuracy\n",
    "print_accuracy(bag_clf, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9f2f7e",
   "metadata": {},
   "source": [
    "### Bagging using random splintering (estimators=500 and max_samples=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "367c80b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of the model is: 76.80 %\n"
     ]
    }
   ],
   "source": [
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(splitter=\"random\", max_leaf_nodes=16),\n",
    "    n_estimators=500,\n",
    "    max_samples=1.0, bootstrap=True, n_jobs=-1)\n",
    "\n",
    "# print accuracy\n",
    "print_accuracy(bag_clf, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e43901",
   "metadata": {},
   "source": [
    "### As we can see there is no dramatic change between the accuracy of bagging and pasting classifiers (even if we changing the number of estimators and max samples [500 and 100 or 100 and 50]),\n",
    "### The accuracy of bagging and pasting classifiers is about ~76 %"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b720168c",
   "metadata": {},
   "source": [
    "# <i>Random Forests</i>\n",
    "\n",
    "* Random forests classifier is an ensemble of decision trees (generally trained via the bagging method)\n",
    "    * ```n_estimators``` is the number if trees\n",
    "    * ```max_leaf_nodes``` is the max size of each tree\n",
    "    * ```n_jobs``` is the number of cpu's to use in the computer (when the parameter is equal to -1 the model will use all the available cpu's)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a08bfd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of the model is: 74.80 %\n"
     ]
    }
   ],
   "source": [
    "rnd_clf = RandomForestClassifier(\n",
    "    n_estimators=500,\n",
    "    max_leaf_nodes=16,\n",
    "    n_jobs=-1)\n",
    "\n",
    "# print accuracy\n",
    "print_accuracy(rnd_clf, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac08e3a",
   "metadata": {},
   "source": [
    "# <i>Boosting</i>\n",
    "\n",
    "### Using AdaBoost:\n",
    "* Parameters:\n",
    "    * classifier to use\n",
    "    * ```n_estimators``` number of ensembles.\n",
    "    * ```algorithm``` version of AdaBoost.\n",
    "    * ```learning_rate``` minimize the cost of the function, gradually the lower is making it better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f93a4d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of the model is: 76.80 %\n"
     ]
    }
   ],
   "source": [
    "ada_clf = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=1),\n",
    "    n_estimators=200,\n",
    "    algorithm=\"SAMME.R\",\n",
    "    learning_rate=0.5)\n",
    "\n",
    "# print accuracy\n",
    "print_accuracy(ada_clf, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f08ee2",
   "metadata": {},
   "source": [
    "### Trying the same with logistic regression but get the same accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3774557b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of the model is: 76.80 %\n"
     ]
    }
   ],
   "source": [
    "ada_clf = AdaBoostClassifier(\n",
    "    LogisticRegression(),\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.5)\n",
    "\n",
    "# print accuracy\n",
    "print_accuracy(ada_clf, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380b64f3",
   "metadata": {},
   "source": [
    "### Using Gradient Boosting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3d6bf681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of the model is: 75.20 %\n"
     ]
    }
   ],
   "source": [
    "gbrt_clf = GradientBoostingClassifier(\n",
    "    max_depth=2,\n",
    "    n_estimators=100,\n",
    "    learning_rate=1.0)\n",
    "\n",
    "# print accuracy\n",
    "print_accuracy(gbrt_clf, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f832d292",
   "metadata": {},
   "source": [
    "# Conclusions:\n",
    "### So far I have tried to build an ensemble learning model that will work with higher accuracy than other simple models, you can see that we have not been able to reach a higher accuracy dramatically\n",
    "\n",
    "# <i>Unsupervised learning</i>\n",
    "\n",
    "### Using K-Means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6f9413cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of the model is: -15880.05 %\n"
     ]
    }
   ],
   "source": [
    "kmeans = KMeans(\n",
    "    init=\"random\",\n",
    "    n_clusters=50,\n",
    "    n_init=10,\n",
    "    max_iter=300,\n",
    "    random_state=42)\n",
    "\n",
    "# print accuracy\n",
    "print_accuracy(kmeans, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921e99c1",
   "metadata": {},
   "source": [
    "### Using Pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "06b95579",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'decode'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-a6815cb16724>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# print accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mprint_accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-8-ab67d0e54609>\u001b[0m in \u001b[0;36mprint_accuracy\u001b[1;34m(clf, X_train, X_test, y_train, y_test)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mprint_accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m# fit the train data to the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m# get the pridictions of X_test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    333\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'passthrough'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 335\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1405\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1406\u001b[0m             \u001b[0mprefer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'processes'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[0;32m   1408\u001b[0m                                \u001b[1;33m**\u001b[0m\u001b[0m_joblib_parallel_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprefer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1409\u001b[0m             path_func(X, y, pos_class=class_, Cs=[C_],\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1039\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1040\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1041\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    857\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    775\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 777\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    778\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[1;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[0;32m    760\u001b[0m                 \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"iprint\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0miprint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"gtol\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"maxiter\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m             )\n\u001b[1;32m--> 762\u001b[1;33m             n_iter_i = _check_optimize_result(\n\u001b[0m\u001b[0;32m    763\u001b[0m                 \u001b[0msolver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt_res\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m                 extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py\u001b[0m in \u001b[0;36m_check_optimize_result\u001b[1;34m(solver, result, max_iter, extra_warning_msg)\u001b[0m\n\u001b[0;32m    241\u001b[0m                 \u001b[1;34m\"    https://scikit-learn.org/stable/modules/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m                 \u001b[1;34m\"preprocessing.html\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 243\u001b[1;33m             ).format(solver, result.status, result.message.decode(\"latin1\"))\n\u001b[0m\u001b[0;32m    244\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_warning_msg\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m                 \u001b[0mwarning_msg\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m\"\\n\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mextra_warning_msg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'decode'"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    (\"kmeans\", KMeans(n_clusters=50)),\n",
    "    (\"log_reg\", LogisticRegression()),\n",
    "])\n",
    "\n",
    "# print accuracy\n",
    "print_accuracy(pipeline, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7943477",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
